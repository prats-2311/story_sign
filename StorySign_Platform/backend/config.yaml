# StorySign ASL Platform Configuration
# This file contains configuration settings for the backend application

# Video capture and processing settings
video:
  width: 320 # Video frame width in pixels (320-1920)
  height: 240 # Video frame height in pixels (240-1080)
  fps: 30 # Target frames per second (10-60)
  format: "JPEG" # Video format codec (MJPG, YUYV, H264)
  quality: 70 # JPEG compression quality (optimized for low latency)

# MediaPipe Holistic model settings
mediapipe:
  min_detection_confidence: 0.5 # Minimum confidence for person detection (0.0-1.0)
  min_tracking_confidence: 0.5 # Minimum confidence for landmark tracking (0.0-1.0)
  model_complexity: 0 # Model complexity: 0=lite/fastest, 1=full, 2=heavy (optimized for speed)
  enable_segmentation: false # Enable pose segmentation mask
  refine_face_landmarks: true # Enable refined face landmark detection

# Server configuration settings
server:
  host: "0.0.0.0" # Server host address
  port: 8000 # Server port number (1024-65535)
  reload: true # Enable auto-reload in development
  log_level: "info" # Logging level (debug, info, warning, error, critical)
  max_connections: 10 # Maximum WebSocket connections (1-100)

# Local vision service configuration
local_vision:
  service_url: "http://localhost:1234" # LM Studio service URL (default port)
  model_name: "google/gemma-3-4b" # Model name as loaded in LM Studio
  service_type: "lm_studio" # Service type: "ollama" or "lm_studio"
  timeout_seconds: 60 # Request timeout in seconds
  max_retries: 3 # Maximum retry attempts
  enabled: true # Enable/disable local vision service

# Ollama LLM service configuration
# backend/config.yaml

ollama_config:
  # Use the official Ollama Cloud API endpoint
  service_url: "https://ollama.com"

  # Specify the correct cloud model you want to use
  story_model: "gpt-oss:20b"
  analysis_model: "gpt-oss:20b"

  # Add your API key here (keep it secret)
  api_key: "f945208978394c218ef31ed075c6c232.ap5HadPbSpSHwURc6anBVAbz"

  # Keep timeouts as they are, or adjust if needed
  timeout_seconds: 60
  max_tokens: 1500
