# StorySign ASL Platform Configuration
# This file contains configuration settings for the backend application

# Video capture and processing settings
video:
  width: 640 # Video frame width in pixels (320-1920)
  height: 480 # Video frame height in pixels (240-1080)
  fps: 30 # Target frames per second (10-60)
  format: "MJPG" # Video format codec (MJPG, YUYV, H264)
  quality: 50 # JPEG compression quality (optimized for low latency)

# MediaPipe Holistic model settings
mediapipe:
  min_detection_confidence: 0.5 # Minimum confidence for person detection (0.0-1.0)
  min_tracking_confidence: 0.5 # Minimum confidence for landmark tracking (0.0-1.0)
  model_complexity: 0 # Model complexity: 0=lite/fastest, 1=full, 2=heavy (optimized for speed)
  enable_segmentation: false # Enable pose segmentation mask
  refine_face_landmarks: true # Enable refined face landmark detection

# Server configuration settings
server:
  host: "0.0.0.0" # Server host address
  port: 8000 # Server port number (1024-65535)
  reload: true # Enable auto-reload in development
  log_level: "info" # Logging level (debug, info, warning, error, critical)
  max_connections: 10 # Maximum WebSocket connections (1-100)

# Local vision service configuration
local_vision:
  service_url: "http://localhost:1234" # LM Studio service URL (default port)
  model_name: "google/gemma-3-4b" # Model name as loaded in LM Studio
  service_type: "lm_studio" # Service type: "ollama" or "lm_studio"
  timeout_seconds: 30 # Request timeout in seconds
  max_retries: 3 # Maximum retry attempts
  enabled: true # Enable/disable local vision service

# Ollama LLM service configuration
ollama:
  service_url: "http://localhost:11434" # Ollama service URL (default port)
  story_model: "llama3.1" # Model name for story generation
  analysis_model: "llama3.1" # Model name for signing analysis
  timeout_seconds: 60 # Request timeout in seconds
  max_tokens: 1000 # Maximum tokens for generation
  temperature: 0.7 # Generation temperature (0.0-2.0)
  max_retries: 3 # Maximum retry attempts
  enabled: true # Enable/disable Ollama service
